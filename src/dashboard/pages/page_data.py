"""Tab 1: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸ã€‚

JVLink DBã®ãƒ†ãƒ¼ãƒ–ãƒ«çŠ¶æ³ã€ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã€ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯çµæœã‚’è¡¨ç¤ºã™ã‚‹ã€‚
JVLinkåŒæœŸã€æ‹¡å¼µãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã®æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã€‚
ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œå¯¾å¿œã€‚
"""

from typing import Any

import pandas as pd
import streamlit as st

from src.dashboard import config_loader
from src.dashboard.components.charts import horizontal_bar_chart
from src.dashboard.components.task_status import show_task_progress
from src.dashboard.components.workflow_bar import mark_step_completed, render_workflow_bar
from src.dashboard.config_loader import PROJECT_ROOT
from src.dashboard.task_manager import TaskManager
from src.data.db import DatabaseManager
from src.data.validator import CheckItem, DataValidator

# ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
JYO_MAP = {
    "01": "æœ­å¹Œ", "02": "å‡½é¤¨", "03": "ç¦å³¶", "04": "æ–°æ½Ÿ", "05": "æ±äº¬",
    "06": "ä¸­å±±", "07": "ä¸­äº¬", "08": "äº¬éƒ½", "09": "é˜ªç¥", "10": "å°å€‰",
}

# å‰Šé™¤å¯èƒ½ãªæ‹¡å¼µãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆfactor_rulesã¯ä¿è­·ï¼‰
DELETABLE_TABLES = {
    "horse_scores": "ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœ",
    "bets": "æŠ•ç¥¨å±¥æ­´",
    "bankroll_log": "è³‡é‡‘ãƒ­ã‚°",
    "backtest_results": "ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ",
    "data_sync_log": "åŒæœŸå±¥æ­´",
    "factor_review_log": "ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å¤‰æ›´å±¥æ­´",
}


def _detect_data_source(db: DatabaseManager) -> dict:
    """ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‹æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚"""
    if not db.table_exists("NL_RA_RACE"):
        return {"source": "empty"}

    rows = db.execute_query("SELECT DISTINCT idJyoCD FROM NL_RA_RACE")
    jyo_codes = {r["idJyoCD"] for r in rows}

    date_info = db.execute_query(
        "SELECT MIN(idYear || idMonthDay) AS min_d, "
        "MAX(idYear || idMonthDay) AS max_d, "
        "COUNT(DISTINCT idYear || idMonthDay) AS days "
        "FROM NL_RA_RACE"
    )
    if not date_info or date_info[0]["days"] is None:
        return {"source": "empty"}

    info = date_info[0]
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿åˆ¤å®š: ä¸­å±±ã®ã¿ + 3æ—¥ä»¥ä¸‹
    is_dummy = jyo_codes == {"06"} and info["days"] <= 3

    return {
        "source": "dummy" if is_dummy else "jvlink",
        "jyo_codes": jyo_codes,
        "min_date": str(info["min_d"]),
        "max_date": str(info["max_d"]),
        "day_count": info["days"],
    }


def _get_table_counts(db: DatabaseManager) -> list[dict]:
    """ä¸»è¦ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—ã™ã‚‹ã€‚"""
    tables = [
        "NL_RA_RACE", "NL_SE_RACE_UMA",
        "NL_O1_ODDS_TANFUKUWAKU", "NL_O2_ODDS_UMAREN",
        "NL_O3_ODDS_WIDE", "NL_O4_ODDS_UMATAN",
        "NL_O5_ODDS_SANREN", "NL_O6_ODDS_SANRENTAN",
        "NL_HR_PAY", "NL_UM_UMA", "NL_KS_KISYU",
    ]
    # å­˜åœ¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’1ã‚¯ã‚¨ãƒªã§ç¢ºèª
    placeholders = ",".join("?" * len(tables))
    existing = db.execute_query(
        f"SELECT name FROM sqlite_master WHERE type='table' AND name IN ({placeholders})",
        tuple(tables),
    )
    existing_set = {r["name"] for r in existing}

    # å­˜åœ¨ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®COUNTã‚’UNION ALLã§ä¸€æ‹¬å–å¾—
    present = [t for t in tables if t in existing_set]
    count_map: dict[str, int] = {}
    if present:
        union_sql = " UNION ALL ".join(
            f"SELECT '{t}' AS tbl, COUNT(*) AS cnt FROM [{t}]" for t in present
        )
        for r in db.execute_query(union_sql):
            count_map[r["tbl"]] = r["cnt"]

    rows = []
    for tbl in tables:
        if tbl in existing_set:
            rows.append({"ãƒ†ãƒ¼ãƒ–ãƒ«": tbl, "ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": count_map.get(tbl, 0), "çŠ¶æ…‹": "OK"})
        else:
            rows.append({"ãƒ†ãƒ¼ãƒ–ãƒ«": tbl, "ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": 0, "çŠ¶æ…‹": "æœªä½œæˆ"})
    return rows


def _get_race_list(db: DatabaseManager) -> pd.DataFrame:
    """ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ã‚’å–å¾—ã™ã‚‹ã€‚"""
    if not db.table_exists("NL_RA_RACE"):
        return pd.DataFrame()

    sql = """
        SELECT
            idYear || '/' || SUBSTR(idMonthDay, 1, 2) || '/' || SUBSTR(idMonthDay, 3, 2) AS æ—¥ä»˜,
            idJyoCD AS å ´CD,
            idRaceNum AS R,
            RaceInfoHondai AS ãƒ¬ãƒ¼ã‚¹å,
            Kyori AS è·é›¢,
            CASE SUBSTR(TrackCD, 1, 1)
                WHEN '1' THEN 'èŠ'
                WHEN '2' THEN 'ãƒ€ãƒ¼ãƒˆ'
                ELSE TrackCD
            END AS ã‚³ãƒ¼ã‚¹,
            SyussoTosu AS é ­æ•°
        FROM NL_RA_RACE r
        ORDER BY idYear DESC, idMonthDay DESC, idJyoCD, CAST(idRaceNum AS INTEGER)
    """
    rows = db.execute_query(sql)
    if not rows:
        return pd.DataFrame()
    df = pd.DataFrame(rows)
    df["ç«¶é¦¬å ´"] = df["å ´CD"].map(JYO_MAP).fillna(df["å ´CD"])
    return df[["æ—¥ä»˜", "ç«¶é¦¬å ´", "R", "ãƒ¬ãƒ¼ã‚¹å", "è·é›¢", "ã‚³ãƒ¼ã‚¹", "é ­æ•°"]]


def _get_sync_log(ext_db: DatabaseManager) -> pd.DataFrame:
    """ãƒ‡ãƒ¼ã‚¿åŒæœŸå±¥æ­´ã‚’å–å¾—ã™ã‚‹ã€‚"""
    if not ext_db.table_exists("data_sync_log"):
        return pd.DataFrame()
    rows = ext_db.execute_query(
        "SELECT started_at, finished_at, status, records_added, error_message "
        "FROM data_sync_log ORDER BY started_at DESC LIMIT 20"
    )
    return pd.DataFrame(rows) if rows else pd.DataFrame()


# ==============================================================
# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç”¨ãƒ©ãƒƒãƒ‘ãƒ¼
# ==============================================================

def _resolve_db_paths() -> tuple[str, str]:
    """ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§DBãƒ‘ã‚¹ã‚’è§£æ±ºã™ã‚‹ï¼ˆsubmitå‰ã«å‘¼ã¶ã“ã¨ï¼‰ã€‚"""
    config = st.session_state.config
    db_cfg = config.get("database", {})
    jvlink_path = str((PROJECT_ROOT / db_cfg.get("jvlink_db_path", "data/jvlink.db")).resolve())
    ext_path = str((PROJECT_ROOT / db_cfg.get("extension_db_path", "data/extension.db")).resolve())
    return jvlink_path, ext_path


def _run_sync_bg(
    jvlink_db_path: str,
    ext_db_path: str,
    exe_path: str,
    timeout_sec: int = 600,
    enable_setup_data: bool = False,
    progress_callback: Any = None,
) -> dict:
    """JVLinkåŒæœŸã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œã™ã‚‹ã€‚"""
    import time

    from src.data.jvlink_sync import JVLinkSyncManager

    jvlink_db = DatabaseManager(jvlink_db_path)
    ext_db = DatabaseManager(ext_db_path)

    if progress_callback:
        progress_callback(0, 4, "åŒæœŸãƒãƒãƒ¼ã‚¸ãƒ£åˆæœŸåŒ–ä¸­...")

    sync_mgr = JVLinkSyncManager(
        jvlink_db=jvlink_db,
        ext_db=ext_db,
        exe_path=exe_path,
        enable_setup_data=enable_setup_data,
    )

    if progress_callback:
        progress_callback(1, 4, "åŒæœŸå‰ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—ä¸­...")

    before = sync_mgr._get_record_counts()

    if progress_callback:
        progress_callback(2, 4, "JVLinkToSQLite.exe ã‚’å®Ÿè¡Œä¸­...")

    t0 = time.time()
    result = sync_mgr.run_sync(timeout_sec=timeout_sec)
    elapsed = time.time() - t0

    if progress_callback:
        progress_callback(3, 4, "åŒæœŸå¾Œãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèªä¸­...")

    after = sync_mgr._get_record_counts()

    # å·®åˆ†è¨ˆç®—
    diff_info = {}
    for tbl in after:
        diff = after[tbl] - before.get(tbl, 0)
        diff_info[tbl] = {"before": before.get(tbl, 0), "after": after[tbl], "diff": diff}

    if progress_callback:
        progress_callback(4, 4, "åŒæœŸå®Œäº†")

    return {
        "status": result["status"],
        "stdout": result.get("stdout", ""),
        "records_added": result.get("records_added", 0),
        "error_message": result.get("error_message", ""),
        "elapsed": elapsed,
        "diff_info": diff_info,
        "validation": result.get("validation", {}),
    }


# ==============================
# ãƒšãƒ¼ã‚¸æœ¬ä½“
# ==============================
st.header("ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
render_workflow_bar("data")

tm: TaskManager = st.session_state.task_manager
jvlink_db: DatabaseManager = st.session_state.jvlink_db
ext_db: DatabaseManager = st.session_state.ext_db
_jvlink_db_path, _ext_db_path = _resolve_db_paths()

# --- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¤å®šãƒãƒŠãƒ¼ ---
data_info = _detect_data_source(jvlink_db)
if data_info["source"] == "dummy":
    st.warning(
        "**ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã™**\n\n"
        "`scripts/seed_dummy_data.py` ã§ç”Ÿæˆã•ã‚ŒãŸæ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
        "2025å¹´1æœˆ ä¸­å±±é–‹å‚¬ 3æ—¥åˆ†ï¼ˆ36ãƒ¬ãƒ¼ã‚¹ï¼‰ã®æ¶ç©ºãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚\n\n"
        "æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ä¸‹ã®ã€ŒJVLink ãƒ‡ãƒ¼ã‚¿åŒæœŸã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚"
    )
elif data_info["source"] == "jvlink":
    min_d = data_info["min_date"]
    max_d = data_info["max_date"]
    jyo_names = ", ".join(JYO_MAP.get(c, c) for c in sorted(data_info["jyo_codes"]))
    st.success(
        f"**JVLinkãƒ‡ãƒ¼ã‚¿**: {min_d[:4]}å¹´{min_d[4:6]}æœˆ ã€œ "
        f"{max_d[:4]}å¹´{max_d[4:6]}æœˆ "
        f"({data_info['day_count']}é–‹å‚¬æ—¥ / {jyo_names})"
    )
    mark_step_completed("data")
else:
    st.info(
        "ãƒ‡ãƒ¼ã‚¿ãŒã¾ã èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n"
        "`run.bat` ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼4ã§ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€"
        "ä¸‹ã®ã€ŒJVLink ãƒ‡ãƒ¼ã‚¿åŒæœŸã€ã‹ã‚‰æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚"
    )

# --- ãƒ†ãƒ¼ãƒ–ãƒ«çŠ¶æ³ ---
st.subheader("ãƒ†ãƒ¼ãƒ–ãƒ«çŠ¶æ³")
table_data = _get_table_counts(jvlink_db)
ext_tables = ["factor_rules", "horse_scores", "bets", "bankroll_log", "backtest_results", "data_sync_log"]
# æ‹¡å¼µãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚ä¸€æ‹¬ã§COUNTå–å¾—
_ext_placeholders = ",".join("?" * len(ext_tables))
_ext_existing = ext_db.execute_query(
    f"SELECT name FROM sqlite_master WHERE type='table' AND name IN ({_ext_placeholders})",
    tuple(ext_tables),
)
_ext_existing_set = {r["name"] for r in _ext_existing}
_ext_present = [t for t in ext_tables if t in _ext_existing_set]
_ext_count_map: dict[str, int] = {}
if _ext_present:
    _ext_union = " UNION ALL ".join(
        f"SELECT '{t}' AS tbl, COUNT(*) AS cnt FROM [{t}]" for t in _ext_present
    )
    for r in ext_db.execute_query(_ext_union):
        _ext_count_map[r["tbl"]] = r["cnt"]
for tbl in ext_tables:
    if tbl in _ext_existing_set:
        table_data.append({"ãƒ†ãƒ¼ãƒ–ãƒ«": f"[æ‹¡å¼µ] {tbl}", "ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": _ext_count_map.get(tbl, 0), "çŠ¶æ…‹": "OK"})
    else:
        table_data.append({"ãƒ†ãƒ¼ãƒ–ãƒ«": f"[æ‹¡å¼µ] {tbl}", "ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°": 0, "çŠ¶æ…‹": "æœªä½œæˆ"})

col1, col2 = st.columns(2)
with col1:
    jvlink_tables = [r for r in table_data if not r["ãƒ†ãƒ¼ãƒ–ãƒ«"].startswith("[æ‹¡å¼µ]")]
    st.markdown("**JVLink DB** (ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å…ƒ)")
    st.dataframe(pd.DataFrame(jvlink_tables), use_container_width=True, hide_index=True)
with col2:
    ext_table_rows = [r for r in table_data if r["ãƒ†ãƒ¼ãƒ–ãƒ«"].startswith("[æ‹¡å¼µ]")]
    st.markdown("**æ‹¡å¼µDB** (åˆ†æçµæœä¿ç®¡å…ˆ)")
    st.dataframe(pd.DataFrame(ext_table_rows), use_container_width=True, hide_index=True)

# --- JVLink ãƒ‡ãƒ¼ã‚¿åŒæœŸ ---
st.divider()
st.subheader("JVLink ãƒ‡ãƒ¼ã‚¿åŒæœŸ")

jvlink_config = st.session_state.config.get("jvlink", {})
exe_path_raw = jvlink_config.get("exe_path", "")
timeout_sec = jvlink_config.get("sync_timeout_sec", 600)

if not exe_path_raw:
    st.info(
        "JVLinkToSQLite.exe ã®ãƒ‘ã‚¹ãŒæœªè¨­å®šã§ã™ã€‚\n\n"
        "`config/config.yaml` ã® `jvlink.exe_path` ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n\n"
        "```yaml\n"
        "jvlink:\n"
        '  exe_path: "./JVLinkToSQLiteArtifact_0.1.2.0.exe"\n'
        "```"
    )
else:
    exe_resolved = (config_loader.PROJECT_ROOT / exe_path_raw).resolve()
    exe_exists = exe_resolved.exists()

    if not exe_exists:
        st.error(f"JVLinkToSQLite.exe ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: `{exe_resolved}`")
    else:
        # åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰
        sync_bat = config_loader.PROJECT_ROOT / "sync_jvlink.bat"
        with st.expander("åˆã‚ã¦åŒæœŸã™ã‚‹å ´åˆï¼ˆJRA-VANåˆ©ç”¨è¦ç´„ã®åŒæ„ãŒå¿…è¦ï¼‰"):
            st.markdown(
                "JV-Linkã‚’åˆã‚ã¦ä½¿ç”¨ã™ã‚‹å ´åˆã€ã¾ãŸã¯JRA-VANåˆ©ç”¨è¦ç´„ãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã¯ã€\n"
                "**æ‰‹å‹•ã§1å›ã ã‘** `sync_jvlink.bat` ã‚’å®Ÿè¡Œã—ã¦åˆ©ç”¨è¦ç´„ã«åŒæ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\n"
                "1. ä¸‹ã®ãƒœã‚¿ãƒ³ã§ `sync_jvlink.bat` ã‚’èµ·å‹•\n"
                "2. ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé–‹ãã€JRA-VANåˆ©ç”¨è¦ç´„ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã‚‹\n"
                "3. åˆ©ç”¨è¦ç´„ã®ãƒªãƒ³ã‚¯ã‚’ç¢ºèª â†’ ãƒã‚§ãƒƒã‚¯ â†’ ã€ŒåŒæ„ã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯\n"
                "4. ãƒ‡ãƒ¼ã‚¿åŒæœŸãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…ã¤ï¼ˆåˆå›ã¯æ•°åˆ†ã€œæ•°ååˆ†ï¼‰\n"
                "5. å®Œäº†å¾Œã€ã“ã®ãƒšãƒ¼ã‚¸ã«æˆ»ã£ã¦ç”»é¢ã‚’æ›´æ–°\n\n"
                "åŒæ„å¾Œã¯ã€ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ã€ŒJVLinkåŒæœŸã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã§è‡ªå‹•åŒæœŸã§ãã¾ã™ã€‚"
            )
            if sync_bat.exists():
                if st.button("sync_jvlink.bat ã‚’å®Ÿè¡Œ", key="btn_run_sync_bat"):
                    import subprocess as sp
                    sp.Popen(
                        ["cmd", "/c", "start", "", str(sync_bat)],
                        cwd=str(config_loader.PROJECT_ROOT),
                    )
                    st.info("åˆ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé–‹ãã¾ã™ã€‚åˆ©ç”¨è¦ç´„ã«åŒæ„ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning(f"`sync_jvlink.bat` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: `{sync_bat}`")

        col_before, col_action = st.columns([2, 1])
        with col_before:
            st.markdown("**ç¾åœ¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°:**")
            for tbl in ["NL_RA_RACE", "NL_SE_RACE_UMA", "NL_HR_PAY"]:
                if jvlink_db.table_exists(tbl):
                    cnt = jvlink_db.execute_query(
                        f"SELECT COUNT(*) as cnt FROM [{tbl}]"
                    )[0]["cnt"]
                    st.text(f"  {tbl}: {cnt:,} ä»¶")
        with col_action:
            st.markdown("**åŒæœŸè¨­å®š:**")
            st.caption(f"exe: {exe_path_raw}")
            st.caption(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {timeout_sec}ç§’")

        st.caption(
            "JVLinkToSQLiteã¯ä¸»ã‚­ãƒ¼ï¼ˆé–‹å‚¬æ—¥+ç«¶é¦¬å ´+å›æ¬¡+æ—¥æ¬¡+ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼‰ã§"
            "è‡ªå‹•çš„ã«UPSERTã‚’è¡Œã†ãŸã‚ã€åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°å›åŒæœŸã—ã¦ã‚‚é‡è¤‡ã¯ç™ºç”Ÿã—ã¾ã›ã‚“ã€‚"
        )

        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰åŒæœŸã®é€²æ—è¡¨ç¤º
        is_syncing = tm.has_running("JVLinkåŒæœŸ")
        show_task_progress("sync_task_id", "sync_result", tm)

        # å‰å›ã®åŒæœŸçµæœè¡¨ç¤º
        sync_result = st.session_state.get("sync_result")
        if sync_result is not None:
            if sync_result["status"] == "SUCCESS":
                st.success(
                    f"åŒæœŸå®Œäº†: {sync_result.get('records_added', 0):,} ä»¶è¿½åŠ  "
                    f"({sync_result['elapsed']:.1f}ç§’)"
                )
            elif sync_result["status"] == "SKIPPED":
                st.info(f"åŒæœŸã‚¹ã‚­ãƒƒãƒ—: {sync_result.get('error_message', '')}")
            else:
                st.error(f"åŒæœŸã‚¨ãƒ©ãƒ¼: {sync_result.get('error_message', '')}")

            # å·®åˆ†è©³ç´°
            diff_info = sync_result.get("diff_info", {})
            if diff_info:
                with st.expander("åŒæœŸçµæœè©³ç´°"):
                    for tbl, info in diff_info.items():
                        mark = f" (+{info['diff']:,})" if info["diff"] > 0 else ""
                        st.text(f"  {tbl}: {info['after']:,} ä»¶{mark}")

                    stdout = sync_result.get("stdout", "")
                    if stdout:
                        st.code(stdout, language="text")

                    validation = sync_result.get("validation", {})
                    if validation and not validation.get("error"):
                        missing = validation.get("missing_tables", [])
                        if missing:
                            st.write(f"  æœªæ¤œå‡ºãƒ†ãƒ¼ãƒ–ãƒ«: {', '.join(missing)}")
                        else:
                            st.write("  å…¨å¿…é ˆãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºèªæ¸ˆã¿")

            if st.button("çµæœã‚’ã‚¯ãƒªã‚¢", key="btn_sync_clear"):
                del st.session_state["sync_result"]
                st.toast("åŒæœŸçµæœã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ", icon="ğŸ—‘ï¸")
                st.rerun()

        btn_label = "åŒæœŸå®Ÿè¡Œä¸­..." if is_syncing else "JVLinkåŒæœŸã‚’å®Ÿè¡Œ"
        if st.button(btn_label, type="primary", key="btn_sync", disabled=is_syncing):
            task_id = tm.submit(
                name="JVLinkåŒæœŸ",
                target=_run_sync_bg,
                kwargs={
                    "jvlink_db_path": _jvlink_db_path,
                    "ext_db_path": _ext_db_path,
                    "exe_path": str(exe_resolved),
                    "timeout_sec": timeout_sec,
                },
            )
            st.session_state["sync_task_id"] = task_id
            st.toast("JVLinkåŒæœŸã‚’é–‹å§‹ã—ã¾ã—ãŸ â€” ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é€²æ—ã‚’ç¢ºèªã§ãã¾ã™", icon="â³")
            st.rerun()

# --- ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ ---
st.divider()
st.subheader("ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯")
st.caption("ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ãƒ»ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãƒ»é‡è¦ã‚«ãƒ©ãƒ æ¬ æãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«é–“æ•´åˆæ€§ã‚’ä¸€æ‹¬ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚")

if st.button("å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ", key="btn_quality"):
    with st.spinner("å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­..."):
        validator = DataValidator(jvlink_db)
        result = validator.run_full_check()
        st.session_state["quality_result"] = result
    st.toast("å“è³ªãƒã‚§ãƒƒã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ", icon="âœ…")

quality_result = st.session_state.get("quality_result")
if quality_result is not None:
    check_items: list[CheckItem] = quality_result.get("check_items", [])

    # --- ã‚µãƒãƒªãƒ¼ ---
    ok_count = sum(1 for c in check_items if c.status == "OK")
    warn_count = sum(1 for c in check_items if c.status == "WARNING")
    err_count = sum(1 for c in check_items if c.status == "ERROR")
    total_count = len(check_items)

    sc1, sc2, sc3, sc4 = st.columns(4)
    sc1.metric("ãƒã‚§ãƒƒã‚¯é …ç›®æ•°", total_count)
    sc2.metric("OK", ok_count)
    sc3.metric("è­¦å‘Š", warn_count)
    sc4.metric("ã‚¨ãƒ©ãƒ¼", err_count)

    if err_count == 0 and warn_count == 0:
        st.success(f"å…¨ {total_count} é …ç›®ã®ãƒã‚§ãƒƒã‚¯ã«åˆæ ¼ã—ã¾ã—ãŸã€‚")
    elif err_count > 0:
        st.error(f"{err_count} ä»¶ã®ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.warning(f"{warn_count} ä»¶ã®è­¦å‘ŠãŒã‚ã‚Šã¾ã™ã€‚")

    # --- ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ ---
    coverage = quality_result.get("data_coverage", {})
    if coverage and coverage.get("race_count"):
        jyo_map = {
            "01": "æœ­å¹Œ", "02": "å‡½é¤¨", "03": "ç¦å³¶", "04": "æ–°æ½Ÿ", "05": "æ±äº¬",
            "06": "ä¸­å±±", "07": "ä¸­äº¬", "08": "äº¬éƒ½", "09": "é˜ªç¥", "10": "å°å€‰",
        }
        with st.expander("ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸", expanded=True):
            cc1, cc2, cc3 = st.columns(3)
            min_d = coverage.get("min_date", "")
            max_d = coverage.get("max_date", "")
            if len(min_d) >= 8:
                date_str = f"{min_d[:4]}/{min_d[4:6]}/{min_d[6:8]} ã€œ {max_d[:4]}/{max_d[4:6]}/{max_d[6:8]}"
            else:
                date_str = f"{min_d} ã€œ {max_d}"
            cc1.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", date_str)
            cc2.metric("é–‹å‚¬æ—¥æ•°", coverage.get("day_count", 0))
            cc3.metric("ãƒ¬ãƒ¼ã‚¹æ•°", f"{coverage.get('race_count', 0):,}")

            venues = coverage.get("venues", {})
            if venues:
                st.markdown("**ç«¶é¦¬å ´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•°:**")
                venue_parts = []
                for code, cnt in sorted(venues.items(), key=lambda x: -x[1]):
                    name = jyo_map.get(code, code)
                    venue_parts.append(f"{name}: {cnt:,}R")
                st.text("  " + " / ".join(venue_parts))

                # ç«¶é¦¬å ´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•°ã‚°ãƒ©ãƒ•
                venue_labels = [JYO_MAP.get(c, c) for c, _ in sorted(venues.items(), key=lambda x: -x[1])]
                venue_values = [cnt for _, cnt in sorted(venues.items(), key=lambda x: -x[1])]
                fig_venue = horizontal_bar_chart(venue_labels, venue_values, "ç«¶é¦¬å ´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•°")
                st.plotly_chart(fig_venue, use_container_width=True)

            entries = coverage.get("horse_entries")
            if entries:
                st.text(f"  å‡ºèµ°é¦¬ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {entries:,} ä»¶")

    # --- ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒã‚§ãƒƒã‚¯çµæœ ---
    status_icon = {"OK": ":white_check_mark:", "WARNING": ":warning:", "ERROR": ":x:"}

    # ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    table_checks = [c for c in check_items if c.category == "table"]
    if table_checks:
        with st.expander(
            f"ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯ ({sum(1 for c in table_checks if c.status == 'OK')}/{len(table_checks)} OK)",
            expanded=err_count > 0,
        ):
            for c in table_checks:
                icon = status_icon.get(c.status, "")
                st.markdown(f"{icon} **{c.name}**: {c.detail}")

    # ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãƒ»æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
    record_checks = [c for c in check_items if c.category in ("record", "column")]
    if record_checks:
        with st.expander(
            f"ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãƒ»æ¬ æå€¤ãƒã‚§ãƒƒã‚¯ ({sum(1 for c in record_checks if c.status == 'OK')}/{len(record_checks)} OK)",
            expanded=any(c.status != "OK" for c in record_checks),
        ):
            for c in record_checks:
                icon = status_icon.get(c.status, "")
                st.markdown(f"{icon} **{c.name}**: {c.detail}")

    # ãƒ†ãƒ¼ãƒ–ãƒ«é–“æ•´åˆæ€§
    consistency_checks = [c for c in check_items if c.category == "consistency"]
    if consistency_checks:
        with st.expander(
            f"ãƒ†ãƒ¼ãƒ–ãƒ«é–“æ•´åˆæ€§ ({sum(1 for c in consistency_checks if c.status == 'OK')}/{len(consistency_checks)} OK)",
            expanded=any(c.status != "OK" for c in consistency_checks),
        ):
            for c in consistency_checks:
                icon = status_icon.get(c.status, "")
                st.markdown(f"{icon} **{c.name}**: {c.detail}")

    # ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ«è©³ç´°
    odds_checks = [c for c in check_items if c.category == "odds"]
    if odds_checks:
        with st.expander(
            f"ã‚ªãƒƒã‚ºãƒ†ãƒ¼ãƒ–ãƒ« ({sum(1 for c in odds_checks if c.status == 'OK')}/{len(odds_checks)} OK)",
            expanded=any(c.status != "OK" for c in odds_checks),
        ):
            for c in odds_checks:
                icon = status_icon.get(c.status, "")
                st.markdown(f"{icon} **{c.name}**: {c.detail}")

    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ãƒã‚§ãƒƒã‚¯çµæœã‚’ã‚¯ãƒªã‚¢", key="btn_quality_clear"):
        del st.session_state["quality_result"]
        st.toast("ãƒã‚§ãƒƒã‚¯çµæœã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ", icon="ğŸ—‘ï¸")
        st.rerun()

# --- ãƒ¬ãƒ¼ã‚¹ä¸€è¦§ ---
st.divider()
st.subheader("ãƒ¬ãƒ¼ã‚¹ä¸€è¦§")
df_races = _get_race_list(jvlink_db)
if df_races.empty:
    st.info(
        "ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n\n"
        "`run.bat` ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼4ã§ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‹ã€"
        "ä¸Šã®ã€ŒJVLink ãƒ‡ãƒ¼ã‚¿åŒæœŸã€ã‹ã‚‰æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã‚“ã§ãã ã•ã„ã€‚"
    )
else:
    st.dataframe(df_races, use_container_width=True, hide_index=True, height=400)
    st.caption(f"å…¨ {len(df_races)} ãƒ¬ãƒ¼ã‚¹")

# --- æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ç®¡ç†ï¼ˆå‰Šé™¤ï¼‰ ---
st.divider()
st.subheader("æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ç®¡ç†")
st.caption(
    "æ‹¡å¼µDBã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å€‹åˆ¥ã«ã‚¯ãƒªã‚¢ã§ãã¾ã™ã€‚"
    "JVLink DBã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¯ä¿è­·ã•ã‚Œã¦ãŠã‚Šã€ã“ã“ã‹ã‚‰ã¯å‰Šé™¤ã§ãã¾ã›ã‚“ã€‚"
)

delete_data = []
for tbl, desc in DELETABLE_TABLES.items():
    cnt = ext_db.execute_query(f"SELECT COUNT(*) as cnt FROM [{tbl}]")[0]["cnt"] if ext_db.table_exists(tbl) else 0
    delete_data.append({"ãƒ†ãƒ¼ãƒ–ãƒ«": tbl, "èª¬æ˜": desc, "ä»¶æ•°": cnt})

st.dataframe(pd.DataFrame(delete_data), use_container_width=True, hide_index=True)

tables_to_delete = st.multiselect(
    "å‰Šé™¤ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠ",
    list(DELETABLE_TABLES.keys()),
    format_func=lambda t: f"{t} ({DELETABLE_TABLES[t]})",
    key="ms_delete",
)

if tables_to_delete:
    total_records = sum(
        d["ä»¶æ•°"] for d in delete_data if d["ãƒ†ãƒ¼ãƒ–ãƒ«"] in tables_to_delete
    )
    st.warning(
        f"**{len(tables_to_delete)} ãƒ†ãƒ¼ãƒ–ãƒ« / {total_records:,} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒå®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã™ã€‚**\n\n"
        "ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ã€‚"
    )
    confirm_text = st.text_input(
        'å‰Šé™¤ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ "delete" ã¨å…¥åŠ›ã—ã¦ãã ã•ã„',
        key="delete_confirm",
    )

    if st.button("ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚’å®Ÿè¡Œ", type="primary", key="btn_delete"):
        if confirm_text == "delete":
            deleted_total = 0
            for tbl in tables_to_delete:
                if ext_db.table_exists(tbl):
                    cnt = ext_db.execute_write(f"DELETE FROM [{tbl}]")
                    deleted_total += cnt
                    st.text(f"  {tbl}: {cnt} ä»¶å‰Šé™¤")
            st.success(f"åˆè¨ˆ {deleted_total:,} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
            st.toast(f"{deleted_total:,} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ", icon="ğŸ—‘ï¸")
            st.rerun()
        else:
            st.error('ç¢ºèªãƒ†ã‚­ã‚¹ãƒˆãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚"delete" ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚')

# --- åŒæœŸå±¥æ­´ ---
st.divider()
st.subheader("ãƒ‡ãƒ¼ã‚¿åŒæœŸå±¥æ­´")
df_sync = _get_sync_log(ext_db)
if df_sync.empty:
    st.info("åŒæœŸå±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.dataframe(df_sync, use_container_width=True, hide_index=True)
